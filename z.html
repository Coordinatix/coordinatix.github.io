<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>3D Voice Nervous System — Fully Fixed & Working (2025)</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    body { margin: 0; background: #07070a; color: #eee; font-family: system-ui; overflow: hidden; }
    #ui { position: absolute; top: 12px; left: 12px; z-index: 20; }
    button { margin-right: 8px; padding: 8px 12px; border: 1px solid #555; border-radius: 6px; background: #333; color: #eee; cursor: pointer; font-size: 14px; }
    button:hover { background: #444; }
    #playBtn { background-color: #28a745; border-color: #28a745; }
    #playBtn:hover { background-color: #218838; }
    #playBtn:disabled { background-color: #555; opacity: 0.6; cursor: not-allowed; }
    #status { margin-left: 12px; font-size: 14px; opacity: 0.9; }
    #tooltip { position: absolute; padding: 8px 10px; background: rgba(0,0,0,0.85); border: 1px solid #444; border-radius: 6px; display: none; pointer-events: none; font-size: 13px; white-space: pre; z-index: 100; }
    canvas { display: block; }
    #audioPlayer { position: absolute; bottom: 16px; left: 16px; z-index: 20; width: 300px; }
  </style>
</head>
<body>
  <div id="ui">
    <button id="startBtn">Start Mic</button>
    <button id="stopBtn" disabled>Stop</button>
    <button id="playBtn" disabled>Play Recording</button>
    <button id="freezeBtn">Freeze Layout</button>
    <button id="exportBtn">Export JSON</button>
    <span id="status">Ready — Click "Start Mic" and speak!</span>
  </div>
  <div id="tooltip"></div>
  <canvas id="scene"></canvas>
  <audio id="audioPlayer" controls></audio>

  <!-- Import Map for ESM (enables clean imports) -->
  <script type="importmap">
    {
      "imports": {
        "three": "https://unpkg.com/three@0.180.0/build/three.module.js",
        "three/addons/": "https://unpkg.com/three@0.180.0/examples/jsm/"
      }
    }
  </script>

  <!-- Bundled Three.js + OrbitControls (fallback if ESM fails, but ESM preferred) -->
  <script src="https://cdn.jsdelivr.net/gh/paulmasson/threejs-with-controls@latest/build/three.min.js"></script>

  <!-- UMAP and Meyda CDNs (verified latest) -->
  <script src="https://cdn.jsdelivr.net/npm/umap-js@1.4.0/dist/umap.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/meyda@5.6.3/dist/web/meyda.min.js"></script>

  <!-- AudioWorklet Processor (inline blob for reliability) -->
  <script type="application/javascript">
    class SyllableProcessor extends AudioWorkletProcessor {
      constructor() {
        super();
        this.buffer = [];
        this.port.onmessage = (e) => {
          if (e.data === 'reset') this.buffer = [];
        };
      }

      process(inputs, outputs, parameters) {
        const input = inputs[0];
        if (!input || input.length === 0) return true;
        const samples = input[0];
        if (samples.length === 0) return true;

        this.buffer.push(...samples);

        // Send in chunks of 2048
        while (this.buffer.length >= 2048) {
          const chunk = this.buffer.slice(0, 2048);
          this.port.postMessage({ samples: chunk });
          this.buffer = this.buffer.slice(2048);
        }
        return true;
      }
    }
    registerProcessor('syllable-processor', SyllableProcessor);
  </script>

  <script type="module">
    // ESM Imports (for modern features)
    import * as THREE from 'three';
    import { OrbitControls } from 'three/addons/controls/OrbitControls.js';

    // Fast YIN-like pitch detection
    function detectPitch(buffer, sampleRate) {
      const SIZE = buffer.length;
      let tauMax = Math.min(1024, Math.floor(sampleRate / 60));
      let minLag = Math.floor(sampleRate / 800);

      let minVal = Infinity;
      let bestLag = 0;

      for (let tau = minLag; tau < tauMax; tau++) {
        let sum = 0;
        for (let i = 0; i < SIZE - tau; i++) {
          const diff = buffer[i] - buffer[i + tau];
          sum += diff * diff;
        }
        if (sum < minVal) {
          minVal = sum;
          bestLag = tau;
        }
      }

      if (minVal < 0.06 && bestLag > 0) {
        const freq = sampleRate / bestLag;
        if (freq > 70 && freq < 800) return freq;
      }
      return 0;
    }

    // Audio Engine with AudioWorklet
    class AudioEngine {
      constructor() {
        this.audioCtx = null;
        this.processorNode = null;
        this.onSyllable = null;
        this.energyWindow = [];
        this.currentSyll = null;
        this.frameIndex = 0;
        this.prevEnergy = 0;
        this.prevPitch = 0;
        this.workletModule = null;
      }

      async start(stream, onSyllable) {
        this.onSyllable = onSyllable;
        this.audioCtx = new AudioContext();
        await this.audioCtx.resume();

        // Create blob URL for the inline AudioWorklet script
        const workletCode = `
          class SyllableProcessor extends AudioWorkletProcessor {
            constructor() {
              super();
              this.buffer = [];
              this.port.onmessage = (e) => {
                if (e.data === 'reset') this.buffer = [];
              };
            }

            process(inputs, outputs, parameters) {
              const input = inputs[0];
              if (!input || input.length === 0) return true;
              const samples = input[0];
              if (samples.length === 0) return true;

              this.buffer.push(...samples);

              while (this.buffer.length >= 2048) {
                const chunk = this.buffer.slice(0, 2048);
                this.port.postMessage({ samples: chunk });
                this.buffer = this.buffer.slice(2048);
              }
              return true;
            }
          }
          registerProcessor('syllable-processor', SyllableProcessor);
        `;
        const blob = new Blob([workletCode], { type: 'application/javascript' });
        const workletUrl = URL.createObjectURL(blob);
        await this.audioCtx.audioWorklet.addModule(workletUrl);

        const source = this.audioCtx.createMediaStreamSource(stream);
        this.processorNode = new AudioWorkletNode(this.audioCtx, 'syllable-processor');

        this.processorNode.port.onmessage = (e) => {
          const samples = e.data.samples;
          const features = Meyda.extract(
            ['rms', 'zcr', 'spectralCentroid', 'spectralFlux', 'mfcc'],
            samples,
            { sampleRate: this.audioCtx.sampleRate }
          );
          if (features) {
            const pitch = detectPitch(samples, this.audioCtx.sampleRate);
            this.processFrame(features, pitch);
          }
        };

        source.connect(this.processorNode);
        this.processorNode.connect(this.audioCtx.destination);
        this.energyWindow = [];
        this.currentSyll = null;
        this.frameIndex = 0;
      }

      processFrame(f, rawPitch) {
        const pitch = rawPitch > 0 ? rawPitch : this.prevPitch;
        this.prevPitch = pitch * 0.7 + this.prevPitch * 0.3;

        const energy = f.rms || 0;
        const smoothedEnergy = energy * 0.9 + this.prevEnergy * 0.1;
        this.prevEnergy = smoothedEnergy;

        this.energyWindow.push(smoothedEnergy);
        if (this.energyWindow.length > 40) this.energyWindow.shift();
        const meanE = this.energyWindow.reduce((a,b)=>a+b,0)/this.energyWindow.length || 0.001;

        const isVoiced = smoothedEnergy > meanE * 1.8 &&
                         (f.zcr || 0) < 0.4 &&
                         pitch > 75 &&
                         (f.spectralFlux || 0) > 0.015;

        const time = this.frameIndex++ * 2048 / this.audioCtx.sampleRate;

        if (isVoiced && !this.currentSyll) {
          this.currentSyll = { start: time, frames: [] };
        }
        if (this.currentSyll) {
          this.currentSyll.frames.push({
            time, energy: smoothedEnergy, pitch,
            mfcc: f.mfcc || new Array(13).fill(0),
            flux: f.spectralFlux || 0
          });

          if (this.currentSyll.frames.length > 8 && smoothedEnergy < meanE * 0.6) {
            this.finalizeSyllable();
          }
        }
      }

      finalizeSyllable() {
        if (!this.currentSyll || this.currentSyll.frames.length < 6) {
          this.currentSyll = null;
          return;
        }
        const frames = this.currentSyll.frames;
        const mfccAvg = frames[0].mfcc.map((_, i) => 
          frames.reduce((s, f) => s + (f.mfcc[i] || 0), 0) / frames.length
        );
        const pitchMean = frames.reduce((s, f) => s + f.pitch, 0) / frames.length;
        const energyMean = frames.reduce((s, f) => s + f.energy, 0) / frames.length;

        const syllable = {
          id: crypto.randomUUID ? crypto.randomUUID() : 'syl-' + Date.now(),
          startTime: this.currentSyll.start,
          endTime: frames[frames.length-1].time,
          features: new Float32Array([...mfccAvg.slice(0,8), energyMean, pitchMean]),
          energyMean,
          pitchMean,
          frameCount: frames.length
        };

        this.onSyllable(syllable);
        this.currentSyll = null;
      }

      stop() {
        if (this.processorNode) {
          this.processorNode.port.postMessage('reset');
          this.processorNode.disconnect();
        }
        if (this.audioCtx) {
          this.audioCtx.close();
        }
      }
    }

    // Reducer3D (UMAP)
    class Reducer3D {
      constructor() {
        this.data = [];
        this.embedded = [];
        this.umap = null;
      }
      add(vec) { this.data.push(Array.from(vec)); }
      fit() {
        if (this.data.length < 5) return;
        try {
          this.umap = new UMAP({ nNeighbors: 6, minDist: 0.1, nComponents: 3 });
          const emb = this.umap.fit(this.data);
          const min = [Infinity,Infinity,Infinity], max = [-Infinity,-Infinity,-Infinity];
          emb.forEach(p => p.forEach((v,i) => { min[i]=Math.min(min[i],v); max[i]=Math.max(max[i],v); }));
          this.embedded = emb.map(p => p.map((v,i) => (v - min[i])/(max[i]-min[i]+1e-6)*2 - 1));
        } catch(e) { console.warn("UMAP fit failed:", e); }
      }
      get() { return this.embedded; }
      knn(k=5) {
        const pts = this.embedded;
        if (!pts || pts.length < 2) return [];
        const n = pts.length;
        const neighbors = [];
        for (let i = 0; i < n; i++) {
          const dists = pts.map((p,j) => j !== i ? {j, d: Math.hypot(...pts[i].map((v,k)=>v-pts[j][k]))} : null).filter(Boolean);
          dists.sort((a,b)=>a.d-b.d);
          neighbors.push(dists.slice(0, k).map(x=>x.j));
        }
        return neighbors;
      }
    }

    // 3D Visualization (using ESM THREE)
    class NervousSystem3D {
      constructor(canvas) {
        this.scene = new THREE.Scene();
        this.scene.background = new THREE.Color(0x07070a);
        this.camera = new THREE.PerspectiveCamera(60, innerWidth/innerHeight, 0.01, 100);
        this.camera.position.set(0,0,5);
        this.renderer = new THREE.WebGLRenderer({canvas, antialias: true});
        this.renderer.setSize(innerWidth, innerHeight);
        this.controls = new OrbitControls(this.camera, canvas);
        this.controls.enableDamping = true;

        const light = new THREE.HemisphereLight(0xffffff, 0x4444aa, 1);
        this.scene.add(light);

        this.nodes = new THREE.Group();
        this.edges = new THREE.Group();
        this.scene.add(this.nodes);
        this.scene.add(this.edges);

        this.tooltip = document.getElementById('tooltip');
        this.raycaster = new THREE.Raycaster();
        this.mouse = new THREE.Vector2();
        canvas.addEventListener('pointermove', e => this.onMove(e));
        canvas.addEventListener('click', e => this.onClick(e));
        window.addEventListener('resize', () => {
          this.camera.aspect = innerWidth/innerHeight;
          this.camera.updateProjectionMatrix();
          this.renderer.setSize(innerWidth, innerHeight);
        });
        this.animate();
      }
      set(nodesData, neighbors) {
        this.nodes.clear();
        this.edges.clear();
        nodesData.forEach(n => {
          const geo = new THREE.SphereGeometry(0.04, 16, 16);
          const mat = new THREE.MeshStandardMaterial({
            color: new THREE.Color(...n.color),
            emissive: new THREE.Color(...n.color).multiplyScalar(0.4)
          });
          const mesh = new THREE.Mesh(geo, mat);
          mesh.position.set(...n.pos);
          mesh.scale.setScalar(0.5 + n.energy*6);
          mesh.userData = n;
          this.nodes.add(mesh);
        });
        const lineMat = new THREE.LineBasicMaterial({color: 0x4488ff, transparent: true, opacity: 0.25});
        neighbors.forEach((list, i) => {
          list.forEach(j => {
            if (j > i) {
              const geo = new THREE.BufferGeometry().setFromPoints([
                new THREE.Vector3(...nodesData[i].pos),
                new THREE.Vector3(...nodesData[j].pos)
              ]);
              this.edges.add(new THREE.Line(geo, lineMat));
            }
          });
        });
      }
      onMove(e) {
        const rect = this.renderer.domElement.getBoundingClientRect();
        this.mouse.x = (e.clientX - rect.left)/rect.width*2 - 1;
        this.mouse.y = -(e.clientY - rect.top)/rect.height*2 + 1;
        this.raycaster.setFromCamera(this.mouse, this.camera);
        const hits = this.raycaster.intersectObjects(this.nodes.children);
        if (hits[0]) {
          const d = hits[0].object.userData;
          this.tooltip.style.display = 'block';
          this.tooltip.style.left = e.clientX + 15 + 'px';
          this.tooltip.style.top = e.clientY + 10 + 'px';
          this.tooltip.textContent = `Syllable ${d.id.slice(0,8)}\nPitch: ${d.pitch.toFixed(0)} Hz\nEnergy: ${d.energy.toFixed(3)}`;
        } else {
          this.tooltip.style.display = 'none';
        }
      }
      onClick(e) {
        const rect = this.renderer.domElement.getBoundingClientRect();
        this.mouse.x = (e.clientX - rect.left)/rect.width*2 - 1;
        this.mouse.y = -(e.clientY - rect.top)/rect.height*2 + 1;
        this.raycaster.setFromCamera(this.mouse, this.camera);
        const hits = this.raycaster.intersectObjects(this.nodes.children);
        if (hits[0]) {
          const d = hits[0].object.userData;
          SpatialAudioEngine.ping(d.pos, d.pitch);
        }
      }
      animate = () => {
        this.controls.update();
        this.renderer.render(this.scene, this.camera);
        requestAnimationFrame(this.animate);
      }
    }

    // Spatial Audio
    class SpatialAudioEngine {
      static ctx = null;
      static init(ctx) { this.ctx = ctx; }
      static ping(pos, freq = 220) {
        if (!this.ctx) return;
        const o = this.ctx.createOscillator();
        const g = this.ctx.createGain();
        const p = this.ctx.createPanner();
        p.panningModel = 'HRTF';
        p.positionX.value = pos[0]*2;
        p.positionY.value = pos[1]*2;
        p.positionZ.value = pos[2]*2;
        o.frequency.value = Math.max(110, Math.min(880, freq));
        o.type = 'sine';
        g.gain.setValueAtTime(0.001, this.ctx.currentTime);
        g.gain.exponentialRampToValueAtTime(0.2, this.ctx.currentTime + 0.01);
        g.gain.exponentialRampToValueAtTime(0.001, this.ctx.currentTime + 0.4);
        o.connect(g).connect(p).connect(this.ctx.destination);
        o.start();
        o.stop(this.ctx.currentTime + 0.4);
      }
    }

    // App Orchestration
    class App {
      constructor() {
        this.canvas = document.getElementById('scene');
        this.vis = new NervousSystem3D(this.canvas);
        this.engine = new AudioEngine();
        this.reducer = new Reducer3D();
        this.syllables = [];
        this.frozen = false;
        this.recorder = null;
        this.chunks = [];

        document.getElementById('startBtn').onclick = () => this.start();
        document.getElementById('stopBtn').onclick = () => this.stop();
        document.getElementById('playBtn').onclick = () => document.getElementById('audioPlayer').play();
        document.getElementById('freezeBtn').onclick = () => {
          this.frozen = !this.frozen;
          document.getElementById('freezeBtn').textContent = this.frozen ? 'Unfreeze' : 'Freeze Layout';
        };
        document.getElementById('exportBtn').onclick = () => this.export();
      }

      async start() {
        try {
          const statusEl = document.getElementById('status');
          statusEl.textContent = 'Requesting microphone...';
          const stream = await navigator.mediaDevices.getUserMedia({audio: { echoCancellation: true, noiseSuppression: true }});
          await this.engine.start(stream, s => this.onSyllable(s));

          const mime = MediaRecorder.isTypeSupported('audio/webm;codecs=opus') ? 'audio/webm;codecs=opus' : 'audio/wav';
          this.recorder = new MediaRecorder(stream, {mimeType: mime});
          this.chunks = [];
          this.recorder.ondataavailable = e => this.chunks.push(e.data);
          this.recorder.onstop = () => {
            const blob = new Blob(this.chunks, {type: mime});
            document.getElementById('audioPlayer').src = URL.createObjectURL(blob);
            document.getElementById('playBtn').disabled = false;
            statusEl.textContent = `Recorded! Syllables: ${this.syllables.length}. Click Play.`;
          };
          this.recorder.start(1000); // Timeslice for chunking

          SpatialAudioEngine.init(this.engine.audioCtx);

          statusEl.textContent = 'Listening — speak now!';
          document.getElementById('startBtn').disabled = true;
          document.getElementById('stopBtn').disabled = false;
        } catch (e) {
          console.error('Mic error:', e);
          document.getElementById('status').textContent = 'Mic access denied: ' + e.message;
        }
      }

      stop() {
        if (this.recorder && this.recorder.state === 'recording') this.recorder.stop();
        this.engine.stop();
        document.getElementById('startBtn').disabled = false;
        document.getElementById('stopBtn').disabled = true;
      }

      onSyllable(s) {
        this.syllables.push(s);
        this.reducer.add(s.features);
        if (this.syllables.length % 3 === 0) this.reducer.fit();

        const emb = this.reducer.get() || this.syllables.map(() => [Math.random()*2-1, Math.random()*2-1, Math.random()*2-1]);
        const neighbors = this.reducer.knn(5);

        const eVals = this.syllables.map(x => x.energyMean);
        const eMin = Math.min(...eVals), eMax = Math.max(...eVals);
        const norm = v => eMax === eMin ? 0.5 : (v - eMin)/(eMax - eMin);

        const nodesData = this.syllables.map((sy, i) => {
          const v = norm(sy.energyMean);
          const col = new THREE.Color().setHSL(0.55 + v*0.3, 1, 0.5);
          return {
            id: sy.id,
            pos: emb[i],
            color: [col.r, col.g, col.b],
            energy: v,
            pitch: sy.pitchMean,
          };
        });

        if (!this.frozen) {
          this.vis.set(nodesData, neighbors);
        }

        document.getElementById('status').textContent = `Syllables: ${this.syllables.length} | Last: ${s.pitchMean.toFixed(0)} Hz @ ${s.startTime.toFixed(1)}s`;
      }

      export() {
        const data = { syllables: this.syllables.map(s => ({...s, features: Array.from(s.features)})) };
        const blob = new Blob([JSON.stringify(data, null, 2)], {type: 'application/json'});
        const a = document.createElement('a');
        a.href = URL.createObjectURL(blob);
        a.download = 'voice-nervous-system.json';
        a.click();
      }
    }

    // Bootstrap
    const app = new App();

    // Cleanup
    window.addEventListener('beforeunload', () => app.stop());
  </script>
</body>
</html>